# ğŸš€ AICodeMentor

Plateforme d'apprentissage de programmation pilotÃ©e par l'IA - GÃ©nÃ©ration et Ã©valuation automatiques d'exercices de programmation avec LLM local.

## ğŸ“‹ Table des matiÃ¨res

1. [PrÃ©sentation](#-prÃ©sentation)
2. [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
3. [Architecture technique](#-architecture-technique)
4. [PrÃ©requis](#-prÃ©requis)
5. [Installation](#-installation)
6. [DÃ©marrage](#-dÃ©marrage)
7. [Configuration](#-configuration)
8. [Utilisation](#-utilisation)
9. [DÃ©pannage](#-dÃ©pannage)
10. [Architecture du code](#-architecture-du-code)
11. [DÃ©veloppement](#-dÃ©veloppement)

---

## ğŸ¯ PrÃ©sentation

AICodeMentor est une plateforme Ã©ducative qui utilise l'intelligence artificielle pour gÃ©nÃ©rer automatiquement des exercices de programmation et fournir des retours personnalisÃ©s aux Ã©tudiants. Le systÃ¨me utilise un modÃ¨le de langage local (llama.cpp) pour fonctionner entiÃ¨rement hors ligne, garantissant la confidentialitÃ© des donnÃ©es.

### Objectifs

- **Pour les enseignants** : CrÃ©er rapidement des exercices de programmation de qualitÃ©
- **Pour les Ã©tudiants** : Pratiquer la programmation avec des retours instantanÃ©s et des indices intelligents
- **Pour les institutions** : Solution open-source, locale et respectueuse de la vie privÃ©e

---

## âœ¨ FonctionnalitÃ©s

### ğŸ‘¨â€ğŸ« Pour les enseignants

- **ğŸ¤– GÃ©nÃ©ration d'exercices par IA**
  - Description en langage naturel â†’ Exercice complet gÃ©nÃ©rÃ© automatiquement
  - Inclut : Ã©noncÃ©, code de dÃ©part, tests unitaires, solution, exemples

- **âœï¸ Ã‰diteur visuel**
  - Ã‰diteur Monaco (mÃªme moteur que VS Code)
  - Modification du code gÃ©nÃ©rÃ© et des tests
  - PrÃ©visualisation en temps rÃ©el

- **ğŸ“Š Gestion des Ã©tudiants**
  - Visualisation des soumissions
  - Statistiques de performance
  - Suivi des progrÃ¨s

- **ğŸ“ Publication d'exercices**
  - ContrÃ´le de la visibilitÃ© (publiÃ©/brouillon)
  - Organisation par thÃ¨me et difficultÃ©
  - Recherche et filtrage

### ğŸ‘¨â€ğŸ“ Pour les Ã©tudiants

- **ğŸ’» Ã‰dition de code en ligne**
  - Ã‰diteur Monaco avec coloration syntaxique
  - Support multi-langages (actuellement Java)
  - Auto-complÃ©tion et validation

- **âœ… Tests automatiques**
  - ExÃ©cution de tests unitaires en temps rÃ©el
  - Retour immÃ©diat sur les rÃ©sultats
  - Affichage des erreurs de compilation et d'exÃ©cution

- **ğŸ’¡ Indices intelligents**
  - Indices personnalisÃ©s gÃ©nÃ©rÃ©s par IA
  - Analyse du code de l'Ã©tudiant
  - Suggestions contextuelles sans rÃ©vÃ©ler la solution

---

## ğŸ—ï¸ Architecture technique

### Frontend

| Technologie | Version | RÃ´le |
|------------|---------|------|
| Vue.js | 3.4+ | Framework frontend |
| Vite | 5.2+ | Build tool et serveur de dÃ©veloppement |
| Bootstrap | 5.3+ | Framework CSS |
| Monaco Editor | 0.45+ | Ã‰diteur de code |
| Vue Router | 4.2+ | Routage |
| Axios | 1.6+ | Client HTTP |

### Backend

| Technologie | Version | RÃ´le |
|------------|---------|------|
| Spring Boot | 3.2+ | Framework backend |
| Spring Data JPA | - | AccÃ¨s aux donnÃ©es |
| H2 Database | - | Base de donnÃ©es (fichier) |
| JUnit 5 | - | ExÃ©cution de tests |
| Maven | 3.6+ | Gestion des dÃ©pendances |

### Intelligence artificielle

| Composant | Description |
|-----------|-------------|
| llama.cpp | Serveur d'infÃ©rence local |
| deepseek-coder-6.7b | ModÃ¨le de langage spÃ©cialisÃ© en code |
| Format | GGUF (quantisÃ© Q2_K, ~2.5GB) |

### Ports des services

| Service | Port | URL |
|---------|------|-----|
| Frontend | 3000 | http://localhost:3000 |
| Backend API | 8080 | http://localhost:8080 |
| llama.cpp | 11435 | http://localhost:11435 |

---

## ğŸ“‹ PrÃ©requis

### Logiciels requis

1. **Java 25 JDK** (obligatoire)
   - TÃ©lÃ©charger depuis [Oracle](https://www.oracle.com/java/technologies/downloads/) ou [OpenJDK](https://jdk.java.net/)
   - **Important** : Configurer la variable d'environnement `JAVA_HOME`

2. **Node.js 18+** (pour le frontend)
   - TÃ©lÃ©charger depuis [nodejs.org](https://nodejs.org/)

3. **Maven 3.6+** (pour le backend)
   - TÃ©lÃ©charger depuis [maven.apache.org](https://maven.apache.org/download.cgi)

### Configuration de Java 25

#### Windows

```powershell
# 1. DÃ©finir JAVA_HOME (session actuelle)
$env:JAVA_HOME = "C:\Program Files\Java\jdk-25"

# 2. Ajouter au PATH
$env:PATH = "$env:JAVA_HOME\bin;$env:PATH"

# 3. VÃ©rifier l'installation
java -version
javac -version
```

**Configuration permanente** :
1. Ouvrir "ParamÃ¨tres systÃ¨me" â†’ "Variables d'environnement"
2. CrÃ©er une variable systÃ¨me : `JAVA_HOME = C:\Program Files\Java\jdk-25`
3. Modifier `Path` : ajouter `%JAVA_HOME%\bin`

#### Linux / macOS

```bash
# 1. DÃ©finir JAVA_HOME (session actuelle)
export JAVA_HOME=/usr/lib/jvm/java-25
export PATH=$JAVA_HOME/bin:$PATH

# 2. VÃ©rifier l'installation
java -version
javac -version
```

**Configuration permanente** :
```bash
# Ajouter Ã  ~/.bashrc ou ~/.zshrc
echo 'export JAVA_HOME=/usr/lib/jvm/java-25' >> ~/.bashrc
echo 'export PATH=$JAVA_HOME/bin:$PATH' >> ~/.bashrc
source ~/.bashrc
```

---

## ğŸ“¦ Installation

### Ã‰tape 1 : Cloner le projet

```bash
git clone <repository-url>
cd ai-code-mentor-main
```

### Ã‰tape 2 : Installer les dÃ©pendances frontend

```bash
npm install
```

### Ã‰tape 3 : TÃ©lÃ©charger le modÃ¨le IA

Le modÃ¨le sera tÃ©lÃ©chargÃ© automatiquement lors de la premiÃ¨re compilation :

```bash
cd backend
mvn process-classes
```

**Note** : Le tÃ©lÃ©chargement prend environ 10-20 minutes (modÃ¨le de ~2.5GB).

Le modÃ¨le sera placÃ© dans : `llama-cpp/models/deepseek-coder-6.7b-instruct.Q2_K.gguf`

---

## ğŸš€ DÃ©marrage

### Option A : DÃ©marrage automatique (recommandÃ© pour dÃ©butants)

**Windows** :
```powershell
.\start-all.bat
```

**Linux / macOS** :
```bash
./start-all.sh
```

Cette commande dÃ©marre automatiquement :
1. llama.cpp (mode CPU)
2. Backend Spring Boot
3. Frontend Vue.js

Attendre que tous les services soient prÃªts, puis accÃ©der Ã  : **http://localhost:3000**

### Option B : DÃ©marrage manuel (recommandÃ© pour GPU)

#### 1. DÃ©marrer llama.cpp

**Mode CPU** (par dÃ©faut) :
```bash
cd llama-cpp
# Windows
.\server.exe -m models\deepseek-coder-6.7b-instruct.Q2_K.gguf -ngl 0 -c 4096 --port 11435

# Linux / macOS
./server -m models/deepseek-coder-6.7b-instruct.Q2_K.gguf -ngl 0 -c 4096 --port 11435
```

**Mode GPU** (voir section [AccÃ©lÃ©ration GPU](#-accÃ©lÃ©ration-gpu) pour les dÃ©tails)

#### 2. DÃ©marrer le backend

```bash
cd backend
mvn spring-boot:run
```

VÃ©rifier que le backend est prÃªt : http://localhost:8080/api/exercises

#### 3. DÃ©marrer le frontend

```bash
npm run dev
```

AccÃ©der Ã  : **http://localhost:3000**

---

## âš™ï¸ Configuration

### Configuration du backend

Fichier : `backend/src/main/resources/application.yml`

```yaml
# Port du serveur
server:
  port: 8080

# Base de donnÃ©es H2
spring:
  datasource:
    url: jdbc:h2:file:./data/testdb
    username: sa
    password: password
  
  # Console H2 (dÃ©veloppement)
  h2:
    console:
      enabled: true
      path: /h2-console

# Configuration LLM
llm:
  provider: llamacpp
  llamacpp:
    base-url: http://localhost:11435
```

### Configuration du frontend

Fichier : `vite.config.js`

Le proxy est configurÃ© pour rediriger `/api` vers `http://localhost:8080` en dÃ©veloppement.

---

## âš¡ AccÃ©lÃ©ration GPU

### NVIDIA GPU (CUDA)

**PrÃ©requis** :
- NVIDIA GPU avec support CUDA
- CUDA Toolkit installÃ©
- Version CUDA de llama.cpp

**DÃ©marrage** :
```bash
cd llama-cpp
.\server.exe -m models\deepseek-coder-6.7b-instruct.Q2_K.gguf -ngl 35 -c 4096 --port 11435
```

**ParamÃ¨tres recommandÃ©s** :
- `-ngl 35` : 35 couches sur GPU (ajuster selon la mÃ©moire GPU)
- `-c 4096` : Taille du contexte
- `-t 4` : Threads CPU (pour les couches restantes)

**VÃ©rification** :
```bash
nvidia-smi  # VÃ©rifier l'utilisation GPU
```

### Intel GPU intÃ©grÃ© (Vulkan)

**PrÃ©requis** :
- Pilotes Vulkan installÃ©s
- Version Vulkan de llama.cpp

**DÃ©marrage** :
```bash
cd llama-cpp
./server -m models/deepseek-coder-6.7b-instruct.Q2_K.gguf -ngl 15 -c 4096 -t 4 --port 11435
```

**ParamÃ¨tres recommandÃ©s** :
- `-ngl 15` : 15 couches sur GPU Vulkan
- RÃ©duire Ã  `-ngl 10` ou `-ngl 5` si mÃ©moire insuffisante

### ParamÃ¨tres de performance

| Mode | Vitesse | Utilisation |
|------|---------|-------------|
| CPU | ~5-6 tokens/s | 100% CPU |
| NVIDIA GPU | ~20-50 tokens/s | GPU + CPU partiel |
| Intel Vulkan | ~8-15 tokens/s | GPU intÃ©grÃ© + CPU |

---

## ğŸ¯ Utilisation

### Workflow enseignant

1. **CrÃ©er un exercice**
   - AccÃ©der Ã  "CrÃ©er un exercice"
   - DÃ©crire l'exercice en langage naturel (ex: "Ã‰crire une fonction qui inverse une chaÃ®ne")
   - L'IA gÃ©nÃ¨re automatiquement :
     - Ã‰noncÃ© dÃ©taillÃ©
     - Code de dÃ©part
     - Tests unitaires
     - Solution
     - Exemples

2. **Modifier et personnaliser**
   - Utiliser l'Ã©diteur pour ajuster le code
   - Modifier les tests si nÃ©cessaire
   - Ajouter des indices ou des explications

3. **Publier**
   - Activer le statut "PubliÃ©"
   - L'exercice devient visible pour les Ã©tudiants

### Workflow Ã©tudiant

1. **Parcourir les exercices**
   - Consulter la liste des exercices publiÃ©s
   - Filtrer par thÃ¨me ou difficultÃ©
   - SÃ©lectionner un exercice

2. **RÃ©soudre l'exercice**
   - Lire l'Ã©noncÃ© et les exemples
   - Ã‰crire le code dans l'Ã©diteur
   - Cliquer sur "ExÃ©cuter les tests"

3. **Obtenir de l'aide**
   - Si les tests Ã©chouent, consulter les erreurs
   - Demander un indice (gÃ©nÃ©rÃ© automatiquement par IA)
   - ItÃ©rer jusqu'Ã  rÃ©solution

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : Port dÃ©jÃ  utilisÃ©

**Solution** :
```bash
# ArrÃªter tous les services
.\stop-all.bat  # Windows
./stop-all.sh   # Linux/Mac

# Attendre 5 secondes, puis redÃ©marrer
.\start-all.bat
```

### ProblÃ¨me : Frontend vide ou erreurs

1. Ouvrir la console du navigateur (F12)
2. VÃ©rifier les erreurs dans l'onglet "Console"
3. VÃ©rifier que le backend est accessible : http://localhost:8080/api/exercises

### ProblÃ¨me : GÃ©nÃ©ration IA Ã©choue

**VÃ©rifier llama.cpp** :
```bash
# Windows PowerShell
Invoke-WebRequest -Uri http://localhost:11435/health

# Linux/Mac
curl http://localhost:11435/health
```

**Si non accessible** :
1. VÃ©rifier que llama.cpp est dÃ©marrÃ©
2. VÃ©rifier le port (11435)
3. VÃ©rifier les logs pour les erreurs

### ProblÃ¨me : GPU ne fonctionne pas

**NVIDIA GPU** :
1. VÃ©rifier CUDA : `nvidia-smi`
2. VÃ©rifier la prÃ©sence de `ggml-cuda.dll` (Windows) ou `libggml-cuda.so` (Linux)
3. Si problÃ¨me, utiliser mode CPU : `-ngl 0`

**Intel GPU** :
1. VÃ©rifier Vulkan : `vulkaninfo` (si installÃ©)
2. Si problÃ¨me, utiliser mode CPU : `-ngl 0`

**Solution universelle** : Utiliser le mode CPU pur
```bash
.\server.exe -m models\deepseek-coder-6.7b-instruct.Q2_K.gguf -ngl 0 -c 4096 --port 11435
```

### ProblÃ¨me : Erreur de compilation Java

**VÃ©rifier Java 25** :
```bash
java -version  # Doit afficher version 25
echo $JAVA_HOME  # Doit pointer vers Java 25
```

**Si problÃ¨me** :
1. RÃ©installer Java 25
2. Reconfigurer `JAVA_HOME`
3. RedÃ©marrer le terminal

---

## ğŸ“š Architecture du code

### Structure du projet

```
ai-code-mentor-main/
â”œâ”€â”€ backend/                          # Backend Spring Boot
â”‚   â”œâ”€â”€ src/main/java/
â”‚   â”‚   â””â”€â”€ com/aicodementor/
â”‚   â”‚       â”œâ”€â”€ controller/           # ContrÃ´leurs REST API
â”‚   â”‚       â”‚   â”œâ”€â”€ ExerciseController.java
â”‚   â”‚       â”‚   â”œâ”€â”€ LLMController.java
â”‚   â”‚       â”‚   â”œâ”€â”€ SubmissionController.java
â”‚   â”‚       â”‚   â”œâ”€â”€ UserController.java
â”‚   â”‚       â”‚   â””â”€â”€ StatsController.java
â”‚   â”‚       â”œâ”€â”€ service/              # Logique mÃ©tier
â”‚   â”‚       â”‚   â”œâ”€â”€ LLMService.java
â”‚   â”‚       â”‚   â””â”€â”€ CodeExecutionService.java
â”‚   â”‚       â”œâ”€â”€ entity/               # EntitÃ©s JPA
â”‚   â”‚       â”‚   â”œâ”€â”€ Exercise.java
â”‚   â”‚       â”‚   â”œâ”€â”€ User.java
â”‚   â”‚       â”‚   â”œâ”€â”€ Submission.java
â”‚   â”‚       â”‚   â””â”€â”€ KnowledgeBase.java
â”‚   â”‚       â”œâ”€â”€ repository/           # AccÃ¨s aux donnÃ©es
â”‚   â”‚       â”œâ”€â”€ dto/                  # Objets de transfert
â”‚   â”‚       â””â”€â”€ config/               # Configuration
â”‚   â”‚           â”œâ”€â”€ CorsConfig.java
â”‚   â”‚           â”œâ”€â”€ GlobalExceptionHandler.java
â”‚   â”‚           â””â”€â”€ DataInitializer.java
â”‚   â””â”€â”€ pom.xml
â”œâ”€â”€ src/                              # Frontend Vue.js
â”‚   â”œâ”€â”€ views/                        # Pages
â”‚   â”‚   â”œâ”€â”€ Home.vue
â”‚   â”‚   â”œâ”€â”€ CreateExercise.vue
â”‚   â”‚   â”œâ”€â”€ ExerciseList.vue
â”‚   â”‚   â”œâ”€â”€ ExerciseDetail.vue
â”‚   â”‚   â””â”€â”€ ExerciseTest.vue
â”‚   â”œâ”€â”€ components/                   # Composants rÃ©utilisables
â”‚   â”‚   â”œâ”€â”€ CodeEditor.vue
â”‚   â”‚   â””â”€â”€ Navbar.vue
â”‚   â”œâ”€â”€ services/                     # Services API
â”‚   â”‚   â”œâ”€â”€ api.js
â”‚   â”‚   â””â”€â”€ llmApi.js
â”‚   â””â”€â”€ router/                       # Routage
â”œâ”€â”€ llama-cpp/                        # Binaires et modÃ¨les
â”‚   â”œâ”€â”€ server.exe / server           # Serveur llama.cpp
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ deepseek-coder-6.7b-instruct.Q2_K.gguf
â”œâ”€â”€ start-all.bat / start-all.sh     # Scripts de dÃ©marrage
â””â”€â”€ package.json
```

### Flux de donnÃ©es

```
Frontend (Vue.js)
    â†“ HTTP
Backend (Spring Boot)
    â†“ JPA
Base de donnÃ©es (H2)
    â†“
Backend
    â†“ HTTP
llama.cpp (LLM local)
```

### API REST

#### Exercices
- `GET /api/exercises` - Liste paginÃ©e des exercices
- `GET /api/exercises/{id}` - DÃ©tails d'un exercice
- `POST /api/exercises` - CrÃ©er un exercice
- `PUT /api/exercises/{id}` - Modifier un exercice
- `DELETE /api/exercises/{id}` - Supprimer un exercice
- `GET /api/exercises/published` - Exercices publiÃ©s

#### LLM
- `POST /api/llm/generate-exercise` - GÃ©nÃ©rer un exercice
- `POST /api/llm/save-exercise` - Sauvegarder un exercice gÃ©nÃ©rÃ©
- `POST /api/llm/execute-tests` - ExÃ©cuter des tests
- `POST /api/llm/get-hint` - Obtenir un indice

#### Soumissions
- `GET /api/submissions` - Liste des soumissions
- `POST /api/submissions` - CrÃ©er une soumission
- `GET /api/submissions/user/{userId}` - Soumissions d'un utilisateur

---

## ğŸ›¡ï¸ Gestion des exceptions

Le projet utilise une gestion centralisÃ©e des exceptions via `GlobalExceptionHandler`.

### Types d'exceptions gÃ©rÃ©es

| Exception | Code HTTP | Usage |
|-----------|-----------|-------|
| `IllegalArgumentException` | 400 | ParamÃ¨tres invalides |
| `DataIntegrityViolationException` | 400 | Violation contraintes DB |
| `ConstraintViolationException` | 400 | Erreur de validation |
| `NoHandlerFoundException` | 404 | Endpoint non trouvÃ© |
| `Exception` | 500 | Erreur gÃ©nÃ©rique |

### Bonnes pratiques

âœ… **Ã€ faire** :
- Utiliser `logger.error()`, `logger.warn()` pour les logs
- Types de retour explicites : `ResponseEntity<Page<Exercise>>`
- Capturer des exceptions spÃ©cifiques
- Laisser les exceptions remonter au `GlobalExceptionHandler`
- Utiliser `@Transactional` pour les opÃ©rations DB

âŒ **Ã€ Ã©viter** :
- `printStackTrace()` ou `System.out.println()`
- `ResponseEntity<?>` (type gÃ©nÃ©rique)
- `catch (Exception e)` gÃ©nÃ©rique
- GÃ©rer manuellement chaque exception

### Hibernate Lazy Loading

**ProblÃ¨me** : AccÃ¨s aux associations lazy aprÃ¨s fermeture de transaction

**Solution** : PrÃ©charger dans la transaction
```java
@Transactional(readOnly = true)
public ResponseEntity<Page<Exercise>> getAllExercises(...) {
    Page<Exercise> exercises = exerciseRepository.findAll(pageable);
    
    // PrÃ©charger avant la fin de la transaction
    exercises.getContent().forEach(ex -> {
        if (ex.getCreator() != null) {
            Hibernate.initialize(ex.getCreator());
            ex.getCreator().getId();
        }
    });
    
    return ResponseEntity.ok(exercises);
}
```

---

## ğŸ’» DÃ©veloppement

### Compilation

**Backend** :
```bash
cd backend
mvn clean compile
```

**Frontend** :
```bash
npm run build
```

### Tests

**Backend** :
```bash
cd backend
mvn test
```

### Base de donnÃ©es

**Console H2** : http://localhost:8080/h2-console

**Connexion** :
- JDBC URL: `jdbc:h2:file:./data/testdb`
- Username: `sa`
- Password: `password`

### Logs

Les logs sont configurÃ©s dans `application.yml` :
```yaml
logging:
  level:
    com.aicodementor: DEBUG
```

---

## ğŸ“„ Licence

MIT License

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Ouvrir une Issue pour signaler un bug
- Proposer une Pull Request
- AmÃ©liorer la documentation

---

**ğŸš€ Pour commencer : ExÃ©cutez `.\start-all.bat` puis accÃ©dez Ã  http://localhost:3000**
